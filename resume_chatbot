
# python3 -m venv weenus # create virtual environmnet named weenus
# source weenus/bin/activate # activate virtual env
# pip install -r requirments.txt #install all requirements, if a requirements.txt file is present
# pip freeze > requirements.txt # after adding new requirements, this add them to the req.txt file

# to run, will need to run the code below in teh *terminal* not in the python code:
# streamlit run /Users/nicoleschultz/Desktop/PythonTest/resume_chatbot.py


import os
import json
import zipfile
import cassandra 
import streamlit as st

from cassandra.cluster import Cluster
from cassandra.auth import PlainTextAuthProvider

from langchain_openai import OpenAI
from langchain_openai import OpenAIEmbeddings
from langchain.vectorstores.cassandra import Cassandra
from langchain.indexes import VectorstoreIndexCreator
from langchain.text_splitter import (
    CharacterTextSplitter,
    RecursiveCharacterTextSplitter,
)
from langchain.docstore.document import Document
from langchain_community.document_loaders import TextLoader, PyPDFLoader


from copy import deepcopy
from tempfile import NamedTemporaryFile



@st.cache_resource 
def create_datastax_connection():
   
  cloud_config= {'secure_connect_bundle': '/Users/nicoleschultz/Documents/secure-connect-reusme.zip'}

  with open('/Users/nicoleschultz/schultznma@gmail.com-token.json') as f:
      secrets = json.load(f)

  CLIENT_ID = secrets['clientId']
  CLIENT_SECRET = secrets['secret']

  # Create an auth provider with your credentials
  auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)
  # Finally, create the cluster and connect
  cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)
  session = cluster.connect()
  return session


session = create_datastax_connection()


#test connection#
row = session.execute("select release_version from system.local").one()

if row:
  print(row[0])
else:
  print("Error")





def main():

    index_placeholder = None
    st.set_page_config(page_title = "Chat with your PDF", page_icon=" ü§ñ ")
    st.header(' ü§ñ Chat with your PDF')

    if "conversation" not in st.session_state:
        st.session_state.conversation = None

    if "activate_chat" not in st.session_state:
        st.session_state.activate_chat = False
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar = message['avatar']):
            st.markdown(message["content"])

    session = create_datastax_connection()

    #os.environ['OPEN_API_KEY'] = "API-key"

    os.environ['OPENAI_API_KEY'] = "INSERT HERE "
    llm = OpenAI(temperature=0)
    openai_embeddings = OpenAIEmbeddings()

    table_name = "resume_table"
    keyspace = "default_keyspace"


    out_index_creator = VectorstoreIndexCreator(
            vectorstore_cls = Cassandra,
            embedding = openai_embeddings,
            text_splitter = RecursiveCharacterTextSplitter(
            chunk_size = 400,
            chunk_overlap = 30),

            vectorstore_kwargs={
            'session': session,
            'keyspace': keyspace,
            'table_name': table_name}
        )      

    with st.sidebar:
        st.subheader('Upload your PDF file')
        docs = st.file_uploader('‚¨ÜÔ∏è Upload your PDF & click to process',
                                accept_multiple_files = False,
                                type=['pdf'])
        if st.button('Process'):
            with NamedTemporaryFile(dir='', siffix='.pdf') as f:
                f.write(docs.getbuffer())
                with st.spinner('Processing'):
                    loader = PyPDFLoader(f.name)
                    pages = loader.load_and_split()
                    pdf_index = out_index_creator.from_loaders([loader])
                    #index_placeholder = deepcopy(pdf_index)
                    if "pdf_index" not in st.session_state:
                        st.session_state.pdf_index = pdf_index
                    st.session_state.activate_chat = True 

    if st.session_state.activate_chat == True:
        if prompt := st.chat_input("Ask your question from the PDF?"):
            with st.chat_message("user", avatar = 'üë§'):
                st.markdown(prompt)
            st.session_state.messages.append({"role": "user",
                                             "avatar" : 'üë§',
                                                "content" : prompt})
        
            index_placeholder = st.session.state.pdf_index
            pdf_response = index_placeholder.query_with_sources(prompt, llm = llm)
            cleaned_response = pdf_response["answer"]
            with st.chat_message("assistant", avatar= 'ü§ñ'):
                st.markdown(cleaned_response)
            st.session_state.messages.append({"role": "assistant",
                                              "avatar" : 'ü§ñ',
                                              "content" : cleaned_response})

        else:
            st.markdown(
                'Upload your PDFs to chat'
                )
            
if __name__ == '__main__':
    main()
